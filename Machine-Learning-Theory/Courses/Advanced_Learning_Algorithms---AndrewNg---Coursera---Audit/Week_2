![NN_1 image](https://github.com/michaelokoroike/Machine-Learning-Portfolio/assets/39680418/e2008604-766b-4488-972e-6c069c2431e6)
WEEK 2: NEURAL NETWORK TRAINING

* NEURAL NETWORK TRAINING
  TensorFlow Implementation
  **** *We are given the code that is used to code a neural network in TensorFlow
       *Step 1: Import tensorflow (and Sequential and Dense from tensorflow)
       *Step 2: Create the simple model (Sequential([Dense(units=25, activation='sigmoid')...])
       *Step 3: Ask tensorflow to compile and choose a loss function (ex: model.compile(loss=BinaryCrossentropy())
       *Step 4: Call the fit function (ex: model.fit(x, y, epochs=100)); epoch is determining how many steps (in gradient descent terms) you
        may want to run
       *Understand how algorithms and things work so that if the training doesn't work correctly initially, you can debug based on your 
        conceptual understanding of what you are doing
  Training Details
  **** *Recap = Loss function is error of one training example; cost function is average error over all training examples
       *The same model training steps done for logistic regression can be done for neural networks (specify how to compute model given input
        x and parameters w and b by defining the model; then specify loss and cost; then train on data to minimize cost)
       *Step 1: Create the simple model (model = Sequential([Dense(...), Dense(...), Dense(...)])
       *Step 2: Use model.compile to define the loss function (model.compile(loss='BinaryCrossentropy'))
       *Step 3: Call function to minimize the cost as a function of the parameters of the neural network (model.fit(X,y, epochs=100))
       *Go over Step 1 in detail; this defines the architecture of the neural network.
       *Go over Step 2 in detail; this specifies the loss function which defines the cost function used for the neural network. Typically
        same as for logistic regression, which is -y(i)*log(f_w[vec],b_(x[vec](i)))-(1 - y(i))*log(1 - (f_w[vec],b_(x[vec](i)))), where y(i)
        is the ground truth (target label) for a training example i, and f_w[vec],b_(x[vec](i)) is the neural network output prediction. In
        TensorFlow, this is referred to as binary crossentropy because the function itself is referred to as crossentropy and binary just
        reemphasizes that it is a binary classification problem. Example for a regression problem would be if you wanted to minimize a 
        squared error loss, and choosing model.compile(loss='MeanSquaredError()'). Cost is with respect to all of the parameters in a 
        neural network.
       *Go over Step 3 in detail; this runs gradient descent (epochs is number of steps to take). The key part of the computation is the
        partial derivative term; TensorFlow ses BACKPROPAGATION to compute the derivative terms.
       *Interesting note; Keras started out as its own project but was merged into TensorFlow. Libraries are mature so good to work
        with them, but also good to implement from scratch and know how things work under the hood.

* ACTIVATION FUNCTIONS
  Alternatives to the Sigmoid Function
  **** *Recap = We've essentially to this point looked at neural networks as algorithms with a bunch of logistic regression equations
        (sigmoid functions) bunched together; but this does not have to be the case.
       *Example = In the demand prediction example, we viewed the parameter of awareness as a binary parameter (they are either aware as
        a customer or they are not), in which case the sigmoid function was used; but there is the possibility it could be the range of
        nonnegative numbers (an infinite scale)...some are aware and more aware than others, while others may be aware but less so
       *Common non-sigmoid function is g(z) = max(0, z) which can take on 0 or any nonnegative value; this is called ReLU (stands for
        Rectified Linear Unit)
       *Another common one is LINEAR ACTIVATION FUNCTION where g(z) = z
       *Just to clarify, when using SIGMOID, g(z) = 1/(1 + e^-z)
  Choosing Activation Functions
  **** *Depending on the ground truth/target label y is, there will be a natural choice for the activation function for the output layer
       *You can choose different activation functions for the hidden layers/different neurons in the neural network
       *Example: When doing a binary classification problem, use sigmoid as the output layer
       *Example: If trying to predict whether the stock price will go up or down, the solution can be positive or negative, in which case
        ReLU wouldn't be great because the prediction would be 0 or higher...but it would be great to use linear activation function which
        can predict positive and negative numbers
       *Example: If trying to predict the price of a house, which can never be negative, using ReLU may be the most efficient
       *ReLU is the most common choice hidden layers; efficient (just requires computing the max of 0 and a computed number), and it only
        goes flat in one part of the graph (as opposed to sigmoid where it goes flat in multiple) which makes gradient descent faster
        (when graphs have places where there are a lot of flat areas, gradient descent is slow)
       *Summary = For output layer (use sigmoid for binary classification; linear for regression that can be positive or negative; ReLU
        if y can only take on positive/nonnegative values); for the hidden layers use ReLU as the default
       *Example code = (model = Sequential([Dense(units=25, activation='relu'), Dense(units=15, activation='relu'), 
                                            Dense(units=1, activation='sigmoid')])
       *Many other activation functions to choose from
  Why Do We Need Activation Functions?
  **** *Video goes over both why we need activation functions and why neural networks don't work if you just use linear activation functions
        in every neuron
       *Using linear activation functions will render the neural network as nothing more than a linear regression function; this would defeat
        the purpose of creating a neural network because it would not be able to fit anything more complex (see video); a linear function
        of a linear function is itself a linear function; if all hidden layers and the output layers are linear then it would be basically
        a linear regression, but if it were linears for all of the hidden layers and a sigmoid for the activation, then it becomes a logistic
        regression (and the neural network doesn't do anything that you can't just do with logistic regression)...this is why a common rule
        of thumb is to not use linear if you don't have to, and to default to ReLU

* MULTICLASS CLASSIFICATION
  Multiclass
  **** *Multiclass classification = Classification problem where you can have more than two outputs possible (not just 0 or 1)
       *Example: If you're trying to determine a zip code, there's 10 possible digits to choose from/recognize (but still cannot be 
        any value)
       *We will look at softmax for this, which is a generalization of the logistic regression algorithm
  Softmax
  **** *Recall = Logistic regression is used when y can take on two possible output values (z = w[vec]*x[vec] + b; a = g(z) = 1/(1+e^(-z))
        = P(y = 1|x), or probability that y is 1 given input x
       *You can essentially with logistic regression have an activation where P(y = 1|x), and also one where P(y = 0|x)...probability that
        y = 0 is essentially 1 - the probability that y is 1 (based on the fact those are the only two outputs)...softmax just
        generalizes this
       *Number of examples of one class/number of examples in total = activation function for a neuron
       *Equation: a_j = e^z_j/(sum of all e^z's) with j as one of the classes, or P(y = j|x[vec])
       *Softmax becomes the same as logistic regression when only two outputs possible
       *Loss function is -log(a_j) if y = j for every instance/class (left half of a bowl)
  Neural Network with Softmax Output
  **** *Video puts the softmax algorithm in the output layer
       *Instead of the output layer only having one neuron, it has typically more than two neurons
       *Softmax is a function of all of the z's (neuronal outputs)
       *Code to implement (see below) = 
          1) import tensorflow; from tensorflow.keras import Sequential; from tensorflow.keras.layers import Dense;
             model = Sequential([Dense(units=25, activation='relu'), Dense(units=15, activation='relu'), 
                                 Dense(units=10, activation='softmax')]) --- (this is specifying the model)
          2) from tensorflow.keras.losses import SparseCategoricalCrossentropy; model.compile(loss=SparseCategoricalCrossentropy()) ---
             (this is specifying the loss and cost function of the model)
          3) model.fit(x,y,epochs=100) (this is training the model on data)
  Improved Implementation of Softmax
  **** *Video shows a better way to implement softmax
       *There can be numerical roundoff errors based on the equation...if x = 3, basically instead of doing 3*x in the code, do 3*3 for
        less rounding error; be more direct (see below)...helps tensorflow avoid overly small or large numbers and gives more flexibility
        to rearrange
       *Only con is it's harder to read
  Classification with Multiple Outputs (Optional)
  **** *Train one neural network with three output labels (multilabel)
       *Multilabel (doea a picture have cars bus dogs etc); vs multiclass (is a picture that of a dog or a cat or a bus)

* ADDITIONAL NEURAL NETWORK CONCEPTS
  Advanced Optimization
  **** *Algorithms other than gradient descent that can help to train your neural network faster
       *Recall the gradient descent formula w = w - alpha*(1/(m)) *(sum of (f_w,b(x(i)) minus y(i))*x(i)) over all of the training examples,
        with alpha as the learning rate
       *If you see that gradient descent is moving in the same direction towards the minimum and you wonder why don't we get gradient
        descent to take bigger steps by increasing alpha? This is the ADAM optimizer (can also make the alpha rate smaller).
       *ADAM stands for ADAptive Moment estimation. Uses a different learning rate for every parameter of the model.
       *If you see that gradient descent is moving in the same direction towards the minimum and you wonder why don't we get gradient
        descent to take bigger steps by increasing alpha (do it); make alpha smaller if oscillates back and forth during gradient descent.
  Additional Layer Types
  **** *Other types of neuron network layers
       *Recap: In the Dense layer the activation of a neuron is based off of all of the activations of the previous layer
       *Another type of layer is CONVOLUTIONAL, where each neuron only looks at part (some) of the activations of the previous layer.
        You would use this because it speeds up computation, and can need less training data when using a convolutional layer. Popularized
        by John Macoun.
       *Example of convolutional layers: Reading EKGs (which is just a list of numbers corresponding to the height of the surface (the 
        flesh above your heart) at different points in time...could be 100 numbers; this is used to classify whether or not a person has
        heart problems/conditions. Hidden convolutional layers could have a neuron look at 1-20, another 11-30, and so on and so forth.
       *Convolutional layers can follow convolutional layers.
       *Transformer, LSTM, attention models...ppl are trying to create new types of more powerful neural network layers.

* BACK PROPAGATION (OPTIONAL)
  What is a Derivative (Optional)?
  **** *Backpropagation algorithm computes cost function with respect to parameters
       *Example: cost function J(w) = w^2, and w = 3; if we increase w by 0.001, w = 3.001 and J(w) = 9.006001 (or, if w increases by 
        0.001 then J(w) increases by 6 * 0.001...if w goes up by epsilon, then J(w) goes up by 6 times epsilon. The way you conclude
        this is the derivative of J(w) with respect to w ([d/dw]J(w)) is equal to 6...this BECOMES MORE VALID WHEN EPSILON IS SMALL, NOT
        BIG.
       *The language to use is "If w increasing by e causes J(w) to increase by k * e, then [d/dw]J(w)) is equal to k".
       *This hearkens us back to gradient descent and w_j (update) = w_j - alpha*([d/dw_j]J(w[vec],b)); if derivative is small, then 
        changing w doesn't make a big difference to the value of j (and so not to bother making a big difference to w_j), but if the 
        derivative of w_j is large, a big change can be made to the cost function by reducing w_j so it is prudent to do so
       *Example is cost function J(w) = w^2, and w = 2; if we increase w by 0.001, w = 2.001 and J(w) = 4.004001 (or, if w increases by 
        0.001 then J(w) increases by 4 * 0.001...
       *Another example is cost function J(w) = w^2, and w = -3; if we increase w by 0.001, w = -2.999 and J(w) = 8.994001 
       (or, if w increases by 0.001 then J(w) increases by -6 * 0.001).
       *When drawing the parabola curve of a J cost function, it's the slope of the line where w equals a certain value
       *Uses examples of if J(w) is w^3, w, or 1/w
       *Compute derivatives using Sympy
       *Again on notation: If J(w) is a function of one variable w, ([d/dw]J(w)); if it is a function of more than one variable, then
        there is a squiggly j used instead of the regular j like above...for a partial derivative.
  Computational Graph (Optional)
  **** *Small neural network example is used
       *It's literally a step by step graph of the calculation of a cost function (activations); using the forward propagation method...
        the first example
       *You use the back propagation method to calculate derivatives; see Chain Rule
       *Example notation = dJ/da = "The derivative of j with respect to a"
       *Back prop is important because you want to know how each variable affects each other; derivatives in early steps can help
        calculate multiple derivatives in the future back prop steps...with n nodes and p parameters, derivatives are computed in 
        n + p steps, rather than n*p steps
  Larger Neural Network Example (Optional)
  **** *The derivatives you feed intothe gradient descent algorithm/ADAM oprtimaization to train the parameters of neural network
