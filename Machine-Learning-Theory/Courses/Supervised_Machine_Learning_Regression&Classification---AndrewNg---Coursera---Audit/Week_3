WEEK 3: CLASSIFICATION

* CLASSIFICATION WITH LOGISTIC REGRESSION
  Motivations
  **** *Examples = Whether an email is spam (categories are Y/N), whether financial transactions are fraudulent (Y/N), is a cancer tumor
        malignant (Y/N). 
       *These are examples of BINARY CLASSIFCATION (y can only be one of two classes)...usually Yes/No, True/False, 0/1 
        (with 0 denoting false and 1 denoting True).
       *0 class = NEGATIVE CLASS (represents the absence of something); 1 class = POSITIVE CLASS (represents the presence of something). Can
        be arbitrary depending on the problem
       *Try to fit a straight line through this problem and it won't work...outlier examples can cause the best fit line to shift, and the
        threshold (DECISION BOUNDARY) also shifts even if it didn't need to
       *A way to try is by using a THRESHOLD (if below a value, predict 0; above a value, predict 1)
       *Linear Regression may get luckyand work well, but often does not in classification problems
       *Interesting = Logistic Regression is mainly for problems with two categories only (binary classification).
  Logistic Regression
  **** *Logistic regression fits an s-shaped curve to the data
       *Based on threshold, likeliness is decided
       *SIGMOID FUNCTION is the important mathematical function to know as it relates to the logistic regression algorithm...it has that 
        s-shaped curve. Also called the LOGISTIC FUNCTION, it outputs between 0 and 1.
       *Sigmoid function formula: g(z) = 1/(1+e^(-z)). When z is large, g(z) as a sigmoid function will be very close to 1; vice versa 
        when it is small/negative, it will be closer to 0.
       *Incorporating sigmoid into the logistic regression algorithm: 1) store w[vec]*x[vec] + b in variable z; 2) next step is to pass
        z through the g(z) = 1/(1+e^(-z)) sigmoid function. You then have the model f_w[vec],b_(x[vec]) = g(w[vec]*x[vec] + b), or
        1/(1+e^-(w[vec]*x[vec] + b)).
       *The way to interpret logistic regression output is to think about it as the probability that the class/label y is 1, given an 
        input x. The probability of it being 0 and the probability of it being 1 have to add up to 100%.
       *Notation typically used in research: f_w[vec],b_(x[vec]) = P(y=1|x[vec]; w[vec], b); states tht w and b are parameters that affect
        the computation of what is the probability that y is equal to 1 given the input feature x
  Decision Boundary
  **** *Common threshold is 0.5 (higher than 0.5 = y-hat is 1; lower than 0.5 = y-hat is 0)
       *Model predicts 1 whenever w[vec]*x[vec] + b >= 0. Model predicts 0 whenever w[vec]*x[vec] + b < 0.
       *DECISION BOUNDARY is where w[vec]*x[vec] + b is equal to 0. Example = when z is w1x1 +w2x2 + b and w1 is 1, w2 is 1 and b is -3;
        this equals z = x1 + x2 - 3 = 0 (at the decision boundary), which equals x1 + x2 = 3...this is the decision boundary.
       *In a non-linear example, when z is w1(x^2)_1 +w2(x^2)_2 + b and w1 is 1, w2 is 1 and b is -1; this equals 
        z = (x^2)_1 + (x^2)_2 - 1 = 0 (at the decision boundary), which equals (x^2)_1 + (x^2)_2 = 1
       *Can get complex depending on the polynomial terms, etc
      
* COST FUNCTION FOR LOGISTIC REGRESSION
  Cost Function for Logistic Regression
  **** *Recall: Cost function gives us a way to measure how well a set of parameters fit training data and gives you a way to try and
        choose better parameters.
       *This video shows that squared error cost function is not ideal for logistic regression; shows which cost function is
       *The example is given of a cancer dataset; what is malignant and what isn't; n is for number of features, i is for number of
        training examples, and it's binary classification, so the target variable y is 0 or 1; and the logistic regression model is 
        f_w[vec],b_(x[vec]) = 1/(1+e^-(w[vec]*x[vec] + b)). The question to ask is, given this dataset, how can you choose w[vec] and 
        b?
       *Squared error cost function works for linear regression because there is typically one minimum (bowl shaped); for 
        logistic regression, it's hilly so there's many local minima that the cost function can get trapped at
       *Example is squared error cost function which can be rewritten as J(w[vec], b) = (1/(m))*((1/2)*sum of (f_w,b(x(i)) minus y(i)) 
        squared over all of the examples)...won't work, but there is a different cost function that can make the cost function of a 
        nonlinear function convex again so convergence to the global minimum can look good
       *The formula is L(f_w[vec],b_(x[vec](i), y(i)) = {-log(f_w[vec],b_(x[vec](i))) if y(i) = 1
                                                         -log(1 - f_w[vec],b_(x[vec](i))) if y(i) = 0}
       *The above formula is the logistic loss function
       *Recall that cost function is the test for how well you are doing on all training examples
       *A natural log curve is almost shaped like half of a downward shaped parabola...the negative of that which is employed by the 
        logistic loss function is like half of an upward facing parabola (soup bowl)
       *F in -log(F) is always between 0 and 1, and 1 is where a logarithmic curve intersects the horizontal axis (10**0 = 1)...so the 
        curve (because logistic functions always have outputs between 0 and 1) essentially only matters between where the curve hits the
        y axis and where it hits the x axis
`      *Loss is lowest when f_w[vec],b_(x[vec](i)) predicts close to the true label
       *Actually, the plot of -log(1 - f_w[vec],b_(x[vec](i))) is like the right half of a soup bowl (which makes sense because loss is
        lowest when f equals 0; when f is 1 it's the left half)
       *Losses approaching the wrong thing approach infinity
       *The logistic loss function makes it a convex and can create a global minimum
       *Proving convexity is beyond the scope of the course
  Simplified Cost Function for Logistic Regression
  **** *Recall = We defined the logistic LOSS function as L(f_w[vec],b_(x[vec](i), y(i)) = {-log(f_w[vec],b_(x[vec](i))) if y(i) = 1
                                                         -log(1 - f_w[vec],b_(x[vec](i))) if y(i) = 0}
       *A simpler way to define it is (in a binary classification model, where the output has to be 0 or 1)
        L(f_w[vec],b_(x[vec](i), y(i)) = -y(i)*log(f_w[vec],b_(x[vec](i)))-(1 - y(i))*log(1 - (f_w[vec],b_(x[vec](i)))); this is because
        the half of the equation that doesn't correlate would be zeroed out
       *The simplified COST function is 1/m * sum of (L(f_w[vec],b_(x[vec](i), y(i))) over all of the training examples; this could also 
        be written as -1/m * sum of [y(i)*log(f_w[vec],b_(x[vec](i)))+(1 - y(i))*log(1 - (f_w[vec],b_(x[vec](i))))] over all of the 
        training examples
       *This cost function is derived from the statistical principle MAXIMUM LIKELIHOOD ESTIMATION, which helps to efficiently find
        parameters for different models

* GRADIENT DESCENT FOR LOGISTIC REGRESSION
  Gradient Descent Implementation
  **** *Recall = The cost function for logistic regression is 
        J(w[vec], b) = -1/m * sum of [y(i)*log(f_w[vec],b_(x[vec](i)))+(1 - y(i))*log(1 - (f_w[vec],b_(x[vec](i))))] over all of the 
        training examples
       *Based on the above cost function, the GRADIENT DESCENT ALGORITHM is still the same
        repeat until convergence {w1 = w1 - alpha*(1/(m)) *(sum of (f_w[vec],b(x[vec](i)) minus y(i))*x1(i))
         .
         .
         .
         wn = wn - alpha*(1/(m)) *(sum of (f_w[vec],b(x[vec](i)) minus y(i))*xn(i)) over all training examples;
         b = b - alpha*(1/(m)) *(sum of (f_w[vec],b(x[vec](i)) minus y(i))) over all of the training examples}.
       *Should also be simulataneous update
       *Looks same as linear regression but is different because function definition for f of x has changed...
        in linear regression it's f_w[vec],b(x[vec]) = (w[vec] * x[vec]) + b.
        in logistic regression it's f_w[vec],b(x[vec]) = 1/(1+e^-(w[vec]*x[vec] + b)).
       *Same as linear, you can monitor convergence, employ vectorization, feature scaling, etc

* THE PROBLEM OF OVERFITTING
  The Problem of Overfitting
  **** *UNDERFITTING = Algorithm doesn't fit training data well; model has high bias (pattern that the algorithm doesn't fit well;
        model has a strong preconception of what the data should look like which is against what the training data shows)
       *GENERALIZATION = Algorithm fits training data well and non-training data well
       *OVERFITTING = Algorithm fits training data extremely well but does not predict non-training data well; model has high variance
        (the algorithm is trying so hard to fit every training example...if the training set were even a little different, then the 
        function that the algorithm fit would end up totally different)
       *Goal of machine learning is to find a model that neither underfits nor overfits (neither high bias or high variance)
       *Above has been for linear regression
       *Below is for logistic regression
       *Same as linear regression except line of importance is decision boundary instead of line of best fit
  Addressing Overfitting
  **** *One way is to collect more training data
       *Another method is selecting features to exclude
       *Another method is REGULARIZATION (reduce the size of the parameters; prevents features from having an overly large effect)
  Cost Function with Regularization
  **** *Regularization essentially adds the large parameters to the cost function, where they are penalized and made close to 0
       *Regularization actually penalizes all of the features of an algorithm
       *To a cost function add (lambda/2m)*sum of parameter squared over all of the parameters of the algorithm; lambda is also
        referred to as a regularization parameter (you have to choose lambda); balances goals of ftting data and keeping parameters small
       *B does not require regularization
       *If lambda is 0 it will overfit, if enormous it will underfit
  Regularized Linear Regression
  **** *Recall the cost function in the prior video regarding regularized linear regression:
        J(w[vec], b) = (1/(2m))*(sum of square of (f_w[vec],b(x[vec](i)) minus y(i))) over all of the training examples +
                       (lambda/2m)*sum of parameter squared over all of the parameters of the algorithm
       *Want to find values for w and b that minimize the regularized cost function...
       *Gradient descent becomes
        repeat until convergence {w1 = w1 - alpha*(1/(m))*((sum of (f_w[vec],b(x[vec](i)) minus y(i))*x1(i)) + ((lambda/m)*w1)
         .
         .
         .
         wn = wn - alpha*(1/(m))*((sum of (f_w[vec],b(x[vec](i)) minus y(i))*xn(i))+((lambda/m)*wn) over all training examples;
         b = b - alpha*(1/(m)) *(sum of (f_w[vec],b(x[vec](i)) minus y(i))) over all of the training examples}
         where a derivatized regularization term is added to the parameters but not b since we don't have to regularize it
       *Math intuition of wn update: rearrange into
        wn = 1wn - (alpha*(lambda/m)*wn) - alpha*(1/(m))*((sum of (f_w[vec],b(x[vec](i)) minus y(i))*xn(i))) over all 
        training examples, which can be rewritten as 
        wn = wn*(1 - alpha*(lambda/m)) - alpha*(1/(m))*((sum of (f_w[vec],b(x[vec](i)) minus y(i))*xn(i))) over all 
        training examples...only difference now is in the update wn is not set to itself minus the alpha, but is multiplied by the 
        (1 - alpha*(lambda/m)) term...alpha and lambda tend to be small numbers and the term ends up being slightly less than 1, which
        slowly but surely shrinks terms
        Additionally the derivative term is (1/(m))*((sum of (f_w[vec],b(x[vec](i)) minus y(i))*xn(i))+((lambda/m)*wn)
