WEEK 2: RECOMMENDER SYSTEMS

* COLLABORATIVE FILTERING
  Making Recommendations
  **** *Example of predicting movie ratings; users making ratings from 1 to 5 stars
       *For recommender systems, there typically will be a number of users and a number of items
       *Notation: n_u is number of users, n_m is number of items, r(i,j) = 1 if a user has rated a movie in the example, y(i,j) = rating
        given by user j to to movie i (only if r(i,j) is 1)
  Using Per-Item Features
  **** *Continuing the movie example; adding romance and action as features to the dataframe/table
       *Notation continued: w_j, b_j is parameters for user j; x_i is feature vector for movie i; for user j and movie i, predict rating
        with w_j*x_i + b_j (linear regression); m_j is number of movies rated by user j; 
       *Cost function is ((1/(2*m_j)) * sum of (w(j) * x(i)+b(j) - y(i,j)) squared for each example) + 
        ((lambda/(2*m_j)) * sum of w_k_j squared for parameters w (b not included for simplicity))...trying to minimize squared error just
        like linear regression; difference between rating predicted and actual rating. i:r(i,j)=1 means looking only at the movies the
        user actually rated. Cost function notation here is min J(w_j, b_j) for user j.
       *Broaden out to all users.
  Collaborative Filtering Algorithm
  **** *Ways to go about finding features when features not given; take a reasonable guess (if you have all the parameters and four 
        ratings), to make the prediction equal to the actual.
       *Cost function is ((1/(2)) * sum of (w(j) * x(i)+b(j) - y(i,j)) squared for each example) + 
        ((lambda/(2)) * sum of x_k_i squared for features x)...trying to minimize squared error just
        like linear regression; difference between rating predicted and actual rating. i:r(i,j)=1 means looking only at the movies the
        user actually rated. Cost function notation here is min J(x_i) for movie i. This is to learn features like romance, etc without
        features being given.
       *
       *Broaden out to all movies; sum it.
       *This is given you haven w and b for all of the users, and wanting to learn x_i features of a movie using gradient descent.
       *Put the two cost functions together; Cost function is ((1/(2)) * sum of (w(j) * x(i)+b(j) - y(i,j)) squared for each example) + 
        ((lambda/(2)) * sum of x_k_i squared for features x) + ((lambda/(2*m_j)) * sum of w_k_j squared for parameters w...trying to minimize 
        squared error just like linear regression; difference between rating predicted and actual rating. i:r(i,j)=1 means looking only at 
        the movies the user actually rated. Cost function notation here is min J(w_j, b_j, x_i) for parameters w and b for user j and features x 
        for movie i.
       *Gradient descent would be 
        repeat until convergence {
         w_i_j = w_i_j - alpha*partial derivative with respect to w_i_j*J(w_j, b_j, x_i) over all training examples;
         b_j = b_j - alpha*partial derivative with respect to b_j*J(w_j, b_j, x_i) over all training examples;
         x_k_i = x_k_i - alpha*partial derivative with respect to x_k_i*J(w_j, b_j, x_i) over all training examples }.
       *Collaborative filtering isusing multiple users rating in a sort of collaboration, which can be used to help users
        in the future.
  Binary Labels: Favs, Likes, and Clicks
  **** *Examples of binary applications = did a user purchase an item after being shown it, did a user like an item, did they spend
        more than 30 seconds with an item, etc? Yes or no answers
       *See video = becomes a logistic regression model

* RECOMMENDER SYSTEMS IMPLEMENTATION DETAIL
  Mean Normalization
  **** *You will have wide ranges of values 1-5 for movies for example; mean normalization will help th algorithm move faster and make
        better predictions
       *Adding a new user who hasn't rated doesn't negatively affect the algorithm because it's only based on who has rated things...
        but also not good because the algorithm will start to think all new users will give only zero star ratings
       *Take the averages of ratings for each movie (?'s are zeros) and put into a vector those means...than subtract the original 
        ratings used to find the means by the mean...then there is a normalized rating table
       *Answer is w(j)*x(i)+b(j) + mean of the movie...?'s end up being the mean of all the ratings of the movie as opposed to 0, which
        is more reasonable
       *Normalize only rows (movie ratings)...normalizing user ratings isn't important if the movie has been rated...if it hasn't been seen
        then it doesn't make sense to ask for ratings and then columns make sense
  Tensorflow Implementation of Collaborative Filtering
  **** *Tensorflow figures out automaically what are the derivatives of a cost function
       *Recall of gradient descent...w = w-alpha*d/dw of J(w,b)...repeat til convergence
       *Given code at 3:00 which uses Tensorflow to calculate derivatives...gradienttape...main work we have with this is to tell it how to
        compute the cost function...called AUTODIFF (package is AUTOGRAD)
       *Done this way because the collaborative filtering algorithm doesn't neatly fit into Dense layers/neural network infrastructure...so we
        we have to implement the cost function ourselves, but the tools of Tensorflow are still helpful
  Finding Related Items
  **** *Like going to Amazon and getting similarly related items sold to you, etc...video shows how it is done
       *In practice, when learning features with an algorithm, they can be hard to interpret...so the features x_i of item i are hard to interpret;
        how you go about it is find item k with features x_k similar to features x_i
       *Math formula is sum of the squared distance between x_l_k - x_l_i vectors...written as ||x_l_k - x_l_i||^2
       *Limitations of collaborative filtering (not good at a cold start problem (ranking new iitems that haven't been rated much, show something
        reasonable to users that have not rated much), no good natural way to use side info (you know a lot about a movie or a user, but can't use 
        much of this)

* CONTENT-BASED FILTERING
  Collaborative Filtering vs Content-Based Filtering
  **** *Collaborative Filtering is recommending items based on ratings of users who gave similar ratings as you; content-based filtering is recommending
        based on features of user and item (limitations of collaborative filtering discussed above) to find a good match
       *Example of movie recommendations; user features may be age, gender, country, movies watched, etc; movie features may be year released, genre, 
        reviews, average rating, etc. User features can become a x_u_j for user j, movie features can become x_m_i for movie i. These vectors can vary in 
        size.
       *Prediction of content-based filtering is with the equation v_u_j * v_m_i (vectors of user features and movie features); derived from computations from
        x_u_j and x_m_i. No b type term is needed, like in wx + b.
       *Example of v_u_j is [4.9,0.1,...,3.0] and first number 4.9 is how much they like romance, and second 0.1 is how they like action movies, etc...and then
        v_m_i is [4.5,0.2,...3.5] with first number capturing how much is it a romance movie, the second how much is it action...the dot product should show how
        much the user would like the movie. These vectors have to be the same size, because a dot product is needed between the two.
  Deep Learning for Content-Based Filtering
  **** *A good way to develop a content-based filtering algorithm is by using deep learning
       *Example is the inputs could start as a 128 neuron vector for the user network and a 256 neuron vector for the movie network, but the output layer for both 
        end up as 32 neuron vectors that match up with each other. They can be drawn together as a single diagram...no separate training procedure for user and movie.
       *You can apply the sigmoid function to the v_u_j * v_m_i prediction equation to predict the probability that y(i,j) is 1
       *Cost function is (v_u_j * v_m_i - y(i,j))^2, or squared difference between predicted and actual ratings over all pairs of i and j, plus a neural network
        regularization term
       *To find movies similar, ||v_m_k - v_m_i||^2 is a way, where vector of movie k is similar to the vector movie i which is already found
       *Mentioned before that neural networks are better than decision tress in the sense you can more easily put multiple neural networks together to work in 
        concert
       *Limitation of the algorithm is it can be computationally expensive
  Recommending from a Large Catalogue
  **** *Streaming sites may have 1000s of movies, millions of ads and songs and products, etc
       *Two steps to recommending from a large catalogue is retrieval and ranking
       *Example of retrieval: for each of the last 10 movies watched by the user find 10 similar; or for most viewed 3 genres find top 10 movies, etc; combining
        those into lists and removing deplicates/items already purchased
       *Ranking is taking the list received and raking using learned model, and then displaying ranked items to users
       *Retrieving more items means better performance but slower recommendations; carry out offline experiments to see how much retrieving more items brings about
        more relevant recommendations
  Ethical Use of Recommender Systems
  **** *Goals of recommender systems: recommend things likely to get high ratings, products likely to be purchased, ads likely to be clicked on (get more per click 
        if a good company), products generating the largest profits, videos leading to maximum watch time, etc
       *Problematic use cases: Squeezing customers of every single dollar (payday lenders), maximizing watch time and amplifying conspiracy theories/hate crimes, 
        maximize profit rather than user experience
       *Good use cases: Good travel experience (travel industry), being more transparent with users (amelioration), filtering out problematic content (amelioration)
  Tensorflow Implementation of Content-Based Filtering
  **** *Create neural networks for users and movies
       *Get the features for users and movies into appropriate neural networks (extract them) and compute the normalized vectors for users and movies
       *Get the dot product between users and movies
       *Finally specify the inputs and outputs of the model, and specify the cost function

* PRINCIPAL COMPONENT ANALYSIS
  Reducing the Number of Features (Optional)
  **** *PCA is typically used for visualization; educe features to visualize what is going on
       *Example: Having a lot of passenger cars; they have a lot of features. Knowledge of the fact width doesnt vary much for cars based on road constraint laws, and
        when you graph based on length on x/horizontal axis and width on y/vertical axis, the distribution of points will be long without much variance vertically. PCA
        essentially would just get rid of width as a variable.
       *In an example when two features are available and both have a lot of variance, you can create another axis
       *3d usually lives on very thin surfaces; you can lower to 2d
  PCA Algorithm (Optional)
  **** *First normalize/scales the features
       *Choose an axis, and that example will be "PROJECTED" onto that axis; axis should capture the variance/spread of the data (axis should not squish the points together)...
        less variance in a badly picked axis means you capture much less information, because the projections onto the new axis are super squished; capture a lot of information
        with less numbers.
       *The best axis with the most variance is called the PRINCIPAL COMPONENT.
       *Project coordinates on the principal component by using a dot product of the original coordinates of a point and a length 1 vector of the principal component axis
       *PCA is not linear regression; with linear regression you are trying to minimize distance across y axis; with PCA there is no ground truth label y aand you're not
        trying to fit a line to have x1 predict x2 you want a line to maximize variance of points...treats x and "y" coordinates equally...with linear regression y is given
        special treatment, but with PCA all axes are treated equally. Maximizing the variance in PCA actually minimizes distance of points from line, like linear regression's 
        goal is.
       *RECONSTRUCTION = PCA can go in reverse to approximate, with approximation being the projection point times the original length 1 vector; the difference is the little
        line segment (distance of point from principal component).
