WEEK 3: Optimization in Neural Networks and Newton's Method

* LESSON 1 - OPTIMIZATION IN NEURAL NETWORKS
  Regression with a Perceptron
  **** *We'll learn about neural networks and how to train them using gradient descent
       *We'll learn an alternate method to gradient descent called Newton's Method
       *This video is about perceptrons, which are the fundamental units of neural networks (note; linear regression can
        be expressed as a perceptron)
       *Motivation from a regression problem (example of housing prices used); you find a line of best fit (the points look like
        they form a line) and this is be able to predict the price of a house, so you wnt to find the best one. If there are
        multiple features and the problem becomes complex (deciphering how each one affects the output) that's where perceptrons come
        in
       *Perceptron = start with input -> plug them into summation function -> get the output y-hat (which will be the prediction). In
        the summation function step, each feature is multiplied by a weight to determine how important it is for the output (w1x1, etc),
        but also a bias term needs to be added (y-hat = w1x1 + w2x2 + b, etc)...goal is to find the best w1, w2, and b (the best weight 
        and bias to optimize prediction)
       *Prediction Function : y-hat = w1x1 + w2x2 + b
       *To find the best weights and bias over time for a function, you need to reduce the errors in the predictions, which is done by
        the LOSS FUNCTION
  Regression with a Perceptron
  **** *In prior video, we wanted to find the best possible line through the dataset points, which would make a ggod prediction; with that
        line, we need to find a way to examine how well the model is doing, and then improve it to get a better one
       *We are shown mean squared error...if we just find the errors (without squaring) we can get negative and positive errors, and in 
        aggregate, you may end up with canceled out errors, which would not be appropriate in the analysis
       *Loss Function : L(y, y-hat) = 1/2*(y - y-hat)^2. The main goal of the loss function is to find the w1, w2, and b that give y-hat
        with the least error
  Regression with a Perceptron - Gradient Descent
  **** *We want to find a prediction function with the best weights and bias that minimizes the loss function L(y, y-hat)...the best model
        that makes the smallest mistakes
       *We minimize L (find the best w1, w2, b) using gradient descent (ex: w1 -> w1 - a*(d_L/d_w1), and same for w2 and b being updated);
        the main aspct is calculating the partial derivatives (d_L/d_w1), (d_L/d_w2), (d_L/d_b)
       *Better model because its a lower loss function
       *Gradient Descent = w1 -> w1 - a*(d_L/d_w1), or w1 -> w1 - a*(-x1(y - y-hat)). Similarly, w2 -> w2 - a*(-x2(y - y-hat)), and
        b -> b - a*(-(y - y-hat)).
  Classification with a Perceptron
  **** *Perceptrons better for binary classfication problems; all you have to do is change the ACTIVATION FUNCTION
       *Just like in regression, first thing you do is plot the points; have your inputs; those inputs go through a prediction function;
        and the y-hat will tell what the model predicts
       *Note: inputs will include weights and biases
       *The activation function takes all the numbers in the input number line and crunch them into the interval 0,1.
       *Note: The sigmoid function is the activation function. Formula is 1/(1 + e^-z).
  Classification with a Perceptron - The sigmoid function
  **** *The sigmoid graph is the s-shaped graph between 0 and 1 on the y axis
       *Formula of sigmoid is 1/(1 + e^-z); if z is very positive it's close to 1, if z is very negative it's close to 0.
       *Derivative of sigmoid function is -1(1 + e^-z)^-2(e^-z)(-1), or 1/((1 + e^-z)^2).
  Classification with a Perceptron - Gradient Descent
  **** *What happens is the perceptron takes inputs, multiplies them by weight functions, applies the sum, and then that sum is
        applied to the sigmoid function to get a prediction (y-hat). We use y-hat with a loss function to find out how far y-hat is
        from what it should be in order to update the weights
       *Best loss function for classification is LOG LOSS
       *We use the error to update the weight and bring the error down
       *Prediction Function (Classification) : y-hat = sigmoid*(w1x1 + w2x2 + b)
       *Loss Function (Classification) : L(y, y-hat) = -y ln(y-hat) - (1-y)ln(1- y-hat)
       *Main goal is finding optimal values for w1, w2, and b
  Classification with a Perceptron - Calculate the Derivatives
  **** *See how w1, w2 affects L...when you know the direction, you can iterate in the direction many times. Use chain rule (in the 
        example, first find d_L/d_y-hat, then d_y-hat/d_w1...this tells us how L is affected by w1. Same for w2 and b.
       *The calculations of the partial deriatives lead to -(y - y-hat) times the input (for the non-bias inputs)...if y and y-hat
        are close enough, the derivative will be small and the step therefore will be small
       *Gradient Descent Function (which you need for optimal values): w1 -> w1 - a*(d_L/d_w1), or w1 -> w1 - a*(-x1(y - y-hat)). 
        Similarly, w2 -> w2 - a*(-x2(y - y-hat)), and b -> b - a*(-(y - y-hat)).
  Classification with a Neural Network
  **** *A neural network is just a bunch of perceptrons organized in layers where the information of the perceptrons are passed to the
        next layer...you train the neural networks with gradient descent, except now with many derivatives.
       *Previous example can only do so well, because it builds a linear boundary between "happy" and "sad", but language is typically
        more complex than that...in that case, more than one perceptron is ideal
       *See video for example
  Classification with a Neural Network - Minimizing Log-loss
  **** *See video; a bunch more chain rule
  Gradient Descent and Backpropagation
  **** *Backpropagation essentially calculates a lot of derivatives using chain rule and updating weights/biases just like before
       *Just longer chain

* LESSON 2 - NEWTON'S METHOD
  Newton's Method
  **** *Newton's method is used to find the zeroes of a function
       *It basically finds where a tangent line hits an axis, and iterates to that point by projecting to that point on the curve 
        (ex: moving horizontally or vertically off of the axis and finding your new point on the curve for a tangent line)
       *Derivative slope = rise/run...this can be manipulated into rise/derivative slope to find the run and the new tangent point
        (numeriacally, xk - x(k+1) = f(xk)/f'(xk))
       *Goal of Newton's Method = find the zeroes of a function (not the minimum). Remember though that to minimize a function g(x),
        you have to find the zeroes of g'(x), which Newton's Method can...therefore using Newton's Method can get you close to minimums
       *Same as gradient desecent for iteration, except instead of starting out with f(x), you start with g'(x) 
        (x(k+1) = xk - (g'(xk)/(g'(xk))'), the second derivative
  Newton's Method: An Example
  **** *Given the former example of g(x) = e^x-log(x), which had a g'(x) of e^x - (1/x) and a minimum of 0.5671; recall that with 
        Newton's Method, you use it to find the zeros of the derivative...(g'(x))' = e^x + (1/(x^2)) is the derivative of the derivative,
        so g'(x) is f(x) and (g'(x))' is f'(x). Start with x0 = 0.05; x1 = x0 - (g'(x0)/(g'(x0))')...iterate this step until you get
        close to the minimum (it actually only takes five steps)
  The Second Derivative
  **** *Newton's Method notates (x(k+1) = xk - (g'(xk)/(g'(xk))'), where g'(xk))' is the second derivative; under Leibniz notation the 
        second derivative is d/dx (df(x)/dx); Lagrange notation is f''(x)
       *Example is distance to velocity to acceleration; velocity is the change of distance with respect to time; acceleration is
        the change of velocity with respect to time. Acceleration is the second derivative in this equation...if you have zero
        acceleration, you have constant velocity.
       *Video showed how in a graph of distance, a curve at 750t^2 will have a velocity of 1500t at the same time; the acceleration
        graph at that point will be at a constant line of 1500
       *Second derivative tells us the curvature of an original function...if a second derivative is positive than 0, it's increasing...
        if it's negative then positive, it's decreasing. A second derivative above zero is a convex (concave up, local minimum, 
        first derivative increasing) function, and below zero is a concave (concave down, local maximum, first derivative decreasing) 
        function
       *Note: If f''(x) = 0, f'(x) is constant...if a derivative (f'(x)) is constant, then it must be a line
  The Hessian
  **** *The Hessian matrix is a matrix of second derivatives
       *When we want to optimize function of many variables using multivariable Newton's method, we use Hessians
       *One variable (f(x)) vs two input variable (f(x,y)); first derivative of 1 variable version is f'(x) (rate of change of f(x)
        with respect to x), but with 2 variables the first derivative can be f_x/y(x,y) (rate of change of the function with 
        respect to x or y) and you can put them together in a vector; second derivative of 1 variable version is f''(x) (rate of
        change of the rate of change of f(x), but with 2 variables
       *Note: partial derivatives do not include terms of orignial function that do not include the term the partial derivative is in
        respect to (ex: f(x,y) = 2x^2 + 3y^2 - xy...f_x(x,y) = 4x - y (3y^2 is not derivative or included in this partial derivative),
        and we would be able to do f_x(x,y) with respect to x or y for the second derivative...four total terms would be in the
        second derivative of f(x,y))
       *Note: Aspects of the second derivative are the exact same typically (f_x(x,y) w.r.t y, or f_y(x,y) w.r.t x)...if the partial
        derivatives are differentiable, these will be the same
       *We are shown the Leibniz and LaGrange version of f_x(x,y) w.r.t y (d2f/dxdy for Leibniz, f_xy(x,y) for LaGrange), etc
       *Hessian matrix is a matrix of these second partial derivatives [f_xx(x,y) f_xy(x,y) | f_yx(x,y) f_yy(x,y)]
  Hessians and Concavity
  **** *Recall concave up (convex) functions have a f''(0) > 0, while concave down (concave) functions have a f''(0) < 0
       *Concave up in two variables looks like f(x,y) = 2x^2 + 3y^2 - xy, which visually appears concave up...the Hessian of f(x,y) -- 
        which is a matrix of the second derivatives of f(x,y) -- is H(0,0) = [4 -1|-1 6]...with one variable, if we wanted to know if a 
        function was concave up, we'd look at f''(0) and see if f''(0) > 0; with two variables, we check the Hessian matrixs sign by 
        checking its eigenvalues
       *Note: Eigenvalue is calculated by finding the determinant of the Hessian minus lambda I (det(H(0,0) - lambda_I)), which equals
        det((4-lambda) -1|-1 (6-lambda))...when you do the multiplication and find the two eigenvalues are positive, this means the matrix
        is positive definite
       *We are shown an example of a concave down function (both eigenvalues are negative, and H(0,0) is a maximum). We are also shown
        a saddle point function, where H(0,0) is neither a maximum or minimum (eigenvalues are split positive and negative)
  Newton's Method for Two Variable
  **** *For 1 variable, x(k+1) = xk - (f'(xk)/(f''(xk))), or x(k+1) = xk - ((f''(xk)^-1)*(f'(xk)))
       *For 2 variables, [x(k+1) | y(k+1)] = [xk | yk] - (H^-1(xk,yk)*f'(xk,yk)), with H being the Hessian matrix
       *An example of f(x,y) = x^4 + 0.8y^4 + 4x^2 + 2y^2 - xy - 0.2x^2 being a convcave up function; start at some point and plug
        into the Hessian and the first derivative...inch closer to the minimum
