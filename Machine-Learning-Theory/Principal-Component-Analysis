A. STANDARD/ABBREVIATION USED FOR THE ALGORITHM
-  Principal Component Analysis (PCA)

B. INFORMATION PROCESSING STRATEGY OF THE ALGORITHM?
- 1. Standardize initial continuous variables
- 2. Compute a covariance matrix
- 3. Find the eigenvectors and eigenvalues of the covariance matrix, to find the principal components
- 4. Create a feature vector to decide the principal components
- 5. Recast data on principal components axes

C. GOAL OF ALGORITHM?
-  To identify patterns in a data set, and then distill the variables down to their most important features so that the data is simplified without losing 
   important traits.
   
D. METHAPHOR FOR THE ALGORITHM?
- Imagine trying to take a picture of a lamp to try to sell it. You want the best angle for the image, that shows the maximum amount of information, so you take from
  multiple angles. Those images are transformations of what is a three dimensional lamp in real life, to a two dimensional image of a lamp.In going from 3D to 2D 
  you lose information, but in some cases of the images you have lost more info than in others...those where you have lost the least are "optimal tranformations".

E. PSEUDOCODE AND/OR FLOWCHART FOR ALGORITHM?
- https://ibug.doc.ic.ac.uk/media/uploads/documents/notes_implementation_component_analysis.pdf

F. RULES OF THUMB FOR USING THE ALGORITHM?
- High correlation between variables


G. WHAT TYPE OF PROBLEM IS THE ALGORITHM BEST FOR?
- Used for: When the number of features in a dataset is too high and there are vairables witin the dataset that are likely highly correlated; high multicollinearity

H. BENCHMARK DATASETS USED TO DESCRIBE THE ALGORITHM?
- Classification problem of weather relying on variables like rainfall and humidity, which are highly correlated
- Classification problem of whether an email is a scam with variables of generic title, content of email, template of email, etc

I. USEFUL RESOURCES FOR LEARNING MORE ABOUT THE ALGORITHM?
- https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html (great simple visualization; my starting point)
- https://www.turing.com/kb/guide-to-principal-component-analysis (steps)
- https://medium.com/sho-jp/linear-algebra-part-6-eigenvalues-and-eigenvectors-35365dc4365a (math)
- https://www.geeksforgeeks.org/dimensionality-reduction/ (pros and cons, info)
- https://openclassrooms.com/en/courses/5869986-perform-an-exploratory-data-analysis/6159451-get-to-grips-with-how-principal-component-analysis-works#:~:text=Principal%20Component%20Analysis%20(or%20PCA,the%20data%20with%20fewer%20variables. (metaphor)




